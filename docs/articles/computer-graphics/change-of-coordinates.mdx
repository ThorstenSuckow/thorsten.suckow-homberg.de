---
title: "Change of Coordinates and Applications to View Matrices"
slug: "change-of-coordinates-and-applications-to-view-matrices"
description: "Geometric Interpretation of Change of Basis"
tags: [computer graphics, linear algebra, opengl]
---
import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';
import {BackButton} from "../../../src/components/BackButton.js";
import {Figure, BibRef, GlosRef, Wiki, Cite} from "../../../src/components/References";
import {Embed} from "../../../src/components/Embed";
import CodeBlock from '@theme/CodeBlock';

import change_of_coordinates from "./img/change-of-coordinates/change-of-coordinates.png";
import change_of_coordinates_code from '!!raw-loader!./plots/change-of-coordinates/change-of-coordinates.py?raw';

export const figures = {
    change_of_coordinates : 1
};



This article introduces the derivation of the _lookAt_-Matrix in OpenGL, which is  a $4x4$-transformation matrix of the form

$$
\boldsymbol{M}_{\text{lookAt}} = \begin{pmatrix}
\boldsymbol{R}_{3 \times 3} & \vec{T}_{3 \times 1} \\
0 & 1
\end{pmatrix}
$$

Here, $\boldsymbol{R}_{3 \times 3}$ denotes a **change-of-coordinates matrix**, and $\vec{T}_{3 \times 1}$ represents a translation vector.

The purpose of the _lookAt_-matrix is to transform coordinates from **world space** to **camera space**, effectively re-expressing world coordinates relative to the camera's point of view:

$$
\vec{v}_\text{camera} = \boldsymbol{M}_{\text{lookAt}}\ \vec{v}_\text{world}
$$

This helps with computing the final image usually appearing on the device being used.

We begin by examining the structure of matrix-vector products, where the **matrix rows are interpreted as the vectors of an orthonormal basis**[^matrixrowsemphased] in $\mathbb{R}^3$.<br />
Next, we introduce the concept of **coordinate vectors** and explain how **change-of-coordinates matrices** are used to map vectors from one coordinate system

$$
B
$$

into another coordinate system

$$
C
$$

Building on these concepts, we conclude by deriving the explicit form of the _lookAt_ matrix to map coordinates between
$V_\text{world}$ and $V_\text{camera}$.


[^matrixrowsemphased]: We intentionally emphasize the phrasing, as it contrasts with the more common convention of interpreting matrix **columns** as basis vectors.



## Interpreting Matrix-Vector Products as Projections


Let $\vec{u}, \vec{v}, \vec{w}$ be the orthonormal vectors of the standard basis $\varepsilon$ in $\mathbb{R}^3$

$$
\begin{alignat*}{3}

\vec{u} &= \begin{pmatrix} 1 \\ 0 \\ 0 \end{pmatrix},\ \vec{v} &= \begin{pmatrix} 0 \\ 1 \\ 0 \end{pmatrix}\ \vec{w} &= \begin{pmatrix} 0 \\ 0 \\ 1 \end{pmatrix}

\end{alignat*}
$$

Let $ \vec{p} = \begin{pmatrix} p_x \\ p_y \\ p_z \end{pmatrix} $ be an arbitrary vector in $ \mathbb{R}^3 $.

We can write $ \vec{p} $ as the matrix-vector product $ \boldsymbol{A} \vec{x} = \vec{p} $, where $ \boldsymbol{A} $ is a $ 3 \times 3 $ matrix whose **rows** represent the vectors $ \vec{u}, \vec{v}, \vec{w} $. Since $A = A^T = I_3$, it immediately follows that $\vec{x} = \vec{p}$.

$$
\begin{alignat*}{3}

\begin{pmatrix}
 \vec{u}_x & \vec{u}_y & \vec{u}_z \\
 \vec{v}_x & \vec{v}_y & \vec{v}_z \\
 \vec{w}_x & \vec{w}_y & \vec{w}_z \end{pmatrix}\begin{pmatrix} p_x \\ p_y \\ p_z\end{pmatrix} =
\begin{pmatrix}
 1 & 0 & 0 \\
 0 & 1 & 0 \\
 0 & 0 & 1 \end{pmatrix}\begin{pmatrix} p_x \\ p_y \\ p_z\end{pmatrix} = \begin{pmatrix} \vec{u} \cdot \vec{p} \\ \vec{v} \cdot \vec{p} \\ \vec{w} \cdot \vec{p} \end{pmatrix} = \begin{pmatrix} p_x \\ p_y \\ p_z\end{pmatrix}
\end{alignat*}
$$


The resulting components $\vec{p}_x, \vec{p}_y, \vec{p}_z$ represent the **scalar projections** of $ \vec{p} $ onto the axes of the standard basis.

Since $\vec{u}$ is a normalized vector, multiplying $\vec{p}_x$ with $\vec{u}$ yields the parallel component of the orthogonal projection of $\vec{p}$ onto $\vec{u}$.<br />
These projections can then be used to reconstruct $\vec{p}$ as a linear combination of the basis vectors $\vec{u}, \vec{v}, \vec{w}$, e.g. for $\vec{u}$:

$$
(\vec{u} \cdot \vec{p}) \vec{u} = (\frac{\vec{u} \cdot \vec{p}}{|\vec{u}|^2}) \vec{u} =  (\frac{\vec{u} \cdot \vec{p}}{1}) \vec{u} = (p_x) \vec{u} = (p_x, 0, 0)^T
$$

and analogously for $\vec{v}, \vec{w}$.

Hence, $\vec{p}$ can be expressed as

$$
(\vec{u} \cdot \vec{p}) \vec{u} + (\vec{v} \cdot \vec{p}) \vec{v} + (\vec{w} \cdot \vec{p}) \vec{w} = \begin{pmatrix}p_x \\ 0 \\ 0 \end{pmatrix} + \begin{pmatrix}0 \\ p_y \\ 0 \end{pmatrix} +\begin{pmatrix}0 \\ 0 \\ p_z \end{pmatrix} = \begin{pmatrix}p_x \\ p_y\\ p_z \end{pmatrix} = \vec{p}
$$

Before we generalize this construction to an arbitrary orthonormal basis, it is worth noting that the **scalar projections** - that is, the **weights** in the above linear combination - are commonly referred to as the components of the corresponding <Wiki name="coordinate vector" file="linearalgebra.coordinatevector" />: The coordinate vector of $\vec{p}$ relative to the standard basis $\varepsilon$ is denoted by[^coordinatevectornotation]

$$
[p]_\varepsilon = \vec{p}_x\begin{bmatrix}1 \\ 0 \\ 0\end{bmatrix} + \vec{p}_y\begin{bmatrix}0 \\ 1 \\ 0\end{bmatrix} + \vec{p}_z\begin{bmatrix}0 \\ 0 \\ 1\end{bmatrix} = \begin{bmatrix}\vec{p}_x \\ \vec{p}_y \\ \vec{p}_z\end{bmatrix}
$$

[^coordinatevectornotation]: We follow _Lay et al._ <Cite name="LLM21" /> with this notation.

:::note Coordinate-Vector Definition
Let $B = \{\vec{b_1}, \vec{b_2}, \ldots, \vec{b_n}\}$ be a basis for the vector space $V = \mathbb{R}^n$.

Then, every vector $\vec{x} \in V$ can be written uniquely as a linear combination:

$$
x = c_1 \vec{b_1} + c_2 \vec{b_2} + \ldots + c_n \vec{b_n}
$$

The vector
$$
    [\vec{x}]_B = \begin{pmatrix}c_1 \\ c_2 \\ \vdots \\ c_n \end{pmatrix}
$$


is then called the **coordinate vector** <BibRef name="LLM21" pp="256" /> of $\vec{x}$ relative to B.
:::


### Generalizing to Arbitrary Bases in 3D

**Claim**:
Let $ \boldsymbol{A} \in \mathbb{R}^{3 \times 3} $ be a matrix whose rows are **orthonormal** basis vectors $ \vec{u}, \vec{v}, \vec{w} $ of $C \subseteq \mathbb{R}^3$.

Then, for any vector $\vec{p} \in \mathbb{R}^3 $, the matrix-vector product
$$
\boldsymbol{A}\vec{p} = \vec{p}'
$$

yields the **scalar projections** of $ \vec{p} $ onto the basis vectors - that is, the coordinates of $\vec{p}$ relative to the orthonormal basis of $C$.

### Proof by Scalar Products

Computing the Matrix-Vector product

$$
\begin{alignat*}{3}

\begin{pmatrix}
 u_x & u_y & u_z \\
 v_x & v_y & v_z \\
 w_x & w_y & w_z \end{pmatrix}\begin{pmatrix} p_x \\ p_y \\ p_z\end{pmatrix} \end{alignat*}
$$

yields the vector

$$
\vec{p'} = \begin{pmatrix}
 u_x p_x + u_y p_y + u_z p_z \\
 v_x p_x + v_y p_y + v_z p_z \\
 w_x p_x + w_y p_y + w_z p_z \end{pmatrix} = \begin{pmatrix} \vec{u} \cdot \vec{p} \\ \vec{v} \cdot \vec{p} \\ \vec{w} \cdot \vec{p}\end{pmatrix}
$$

Each component is the scalar projection of $ \vec{p} $ onto the basis vector $ \vec{u}, \vec{v}, \vec{w}  $.

Intuitively, the components in the resulting vector $\vec{p'}$ show the _scalar amount_ showing into the respective direction.

To confirm that these projections are aligned with the original basis vectors, we rewrite:


$$
\vec{p}' = (\vec{u} \cdot \vec{p}) \vec{u} + (\vec{v} \cdot \vec{p}) \vec{v} + (\vec{w} \cdot \vec{p}) \vec{w}
$$

Computing the dot product with a specific basis vector isolates its corresponding contribution:



$$
\begin{alignat*}{3}
\vec{p'} \cdot \vec{u} &= (\vec{u} \cdot \vec{p})(\vec{u} \cdot \vec{u}) +  (\vec{v} \cdot \vec{p})(\vec{v}  \cdot \vec{u}) + (\vec{w} \cdot \vec{p})(\vec{w}  \cdot \vec{u})\\
&= (\vec{u} \cdot \vec{p})(1) +  (\vec{v} \cdot \vec{p})(0) + (\vec{w} \cdot \vec{p})(0) \\
& = \vec{u} \cdot \vec{p}
\end{alignat*}
$$

The same holds for $ \vec{v} $ and $ \vec{w} $.

Thus, the vector $ \vec{p}' = \boldsymbol{A} \vec{p} $ contains exactly the scalar projections of $ \vec{p} $ onto the axes of the orthonormal basis, and the original vector can be reconstructed as a linear combination of the basis vectors scaled by those projections. $\Box$



### Proof via Change-of-Coordinates


 We begin by introducing the **Change-of-Coordinate Matrix Theorem**.

:::note Change-of-Coordinate Matrix Theorem
 [^theoremref]Let $B = \{\vec{b}_1, \vec{b}_2, \ldots, \vec{b}_n\}$ and $C =  \{\vec{c}_1, \vec{c}_2, \ldots, \vec{c}_n\}$ be bases of a vector space $V$. Then there is a unique $n \times n$ matrix  $\underset{C \leftarrow B}{\boldsymbol{P}}$ such that

 $$
 \underset{C \leftarrow B}{\boldsymbol{P}} [\vec{x}]_B = [\vec{x}]_C
 $$

 The columns of $\underset{C \leftarrow B}{\boldsymbol{P}}$ are the $C$-coordinate vectors of the vectors in the basis $B$ [^bcoordinatevectors].<br />
 That is,

 $$
 \underset{C \leftarrow B}{\boldsymbol{P}} = \begin{pmatrix}[\vec{b_1}]_C &[\vec{b_2}]_C & \ldots & [\vec{b_n}]_C \end{pmatrix}
 $$

 **Proof (Existence):**
 Given $\vec{v} \in V$, there exists scalars $x_1, x_2, \ldots, x_n$ such that

 $$
 \vec{v} = x_1\vec{b_1} + x_2\vec{b_2} + \ldots + x_n\vec{b_n}
 $$

By the rules of matrix-vector multiplication, we can rewrite this equation to

 $$
 \vec{v} = \begin{pmatrix} \vec{b_1} & \vec{b_2} & \ldots & \vec{b_n} \end{pmatrix} \begin{pmatrix}x_1 \\ x_2 \\ \vdots \\ x_n \end{pmatrix}
 $$

 Clearly, $(x_1, x_2, \ldots, x_n)^T$ represents $[\vec{v}]_B$, as it is the coordinate vector of $\vec{v}$ relative to the basis $B$.

Since $B$ and $C$ are bases for the same vector space, each $\vec{b_i}$ can be expressed as a linear combination of vectors in $C$, that is, via $[\vec{b_i}]_C$.
 <br />
 Hence, we substitute $\vec{b_i}$ with $[\vec{b_i}]_C, 1 \leq i \leq n$.

 $$
 [\vec{v}]_C = \begin{pmatrix} [\vec{b_1}]_C & [\vec{b_2}]_C & \ldots & [\vec{b_n}]_C \end{pmatrix} \begin{pmatrix}x_1 \\ x_2 \\ \vdots \\ x_n \end{pmatrix}
 $$

We denote the left-hand matrix as

$$
\underset{C \leftarrow B}{\boldsymbol{P}}
$$

Multiplying the contained coordinate vectors with the coordinates of $\vec{v}$ relative to $B$ then yields the coordinates of $\vec{v}$ relative to $C$, as per rules of linear transformation.


$$
 [\vec{v}]_C = \underset{C \leftarrow B}{\boldsymbol{P}} [\vec{v}]_B
$$
$\Box$

**Proof (Uniqueness)**:

Let $[\vec{v}]_C = \boldsymbol{M} [\vec{v}]_B\ \forall\ \vec{v} \in V$.

Replace $\vec{v}$ with $\vec{b_1}$. Then $[\vec{b_1}]_B = \vec{e_1}$, i.e. $(1, 0, \ldots, 0)^T$ of the standard basis. Hence, the first column of $\boldsymbol{M}$ must be $[\vec{b_1}]_C$ to satisfy

$$
[\vec{b_1}]_C = \boldsymbol{M} \vec{e_1}
$$

Equally, for any $i > 1$, the $i$th column of $\boldsymbol{M}$ must be $[\vec{b_i}]_C$, since $[\vec{b_i}]_B = \vec{e_i}$:

$$
[\vec{b_i}]_C = \boldsymbol{M} \vec{e_i}
$$

Since any vector $\vec{v} \in V$ is a linear combination of (linearly independent) basis vectors, the resulting coordinate vector in $C$ can be written as a sum of the columns of $\boldsymbol{M}$ weighted by the coordinates of $[\vec{v}]_B$.<br />
 Because the columns of $\boldsymbol{M}$ are uniquely determined by the basis vectors, the resulting change-of-coordinates matrix $\boldsymbol{M}$ is unique.

$\Box$

:::

[^theoremref]: See <Cite name="LLM21" pp="275" />
[^bcoordinatevectors]: That is, the coordinate vector of $\vec{x}$ relative to $C$.

We now show that multiplying a vector $\vec{p}$ - that is, its coordinate representation $[\vec{p}]_\varepsilon$ in the standard basis - with $\boldsymbol{A}$ yields a vector whose components are the scalar projections of $\vec{p}$ relative to an orthonormal basis $C$, via a change-of-coordinates matrix.<br />
 This approach emphasizes the geometric interpretation of the transformation as a coordinate conversion from the standard basis to an arbitrary orthonormal basis and provides the theoretical foundation for the _lookAt_ matrix introduced later.

We begin by computing the change-of-coordinate matrix $\underset{\varepsilon \leftarrow C}{M}$.


This matrix satisfies the following condition:

$$
\underset{\varepsilon \leftarrow C}{\boldsymbol{M}} [\vec{p}]_C = [\vec{p}]_\varepsilon
$$

We can rewrite $\underset{\varepsilon \leftarrow C}{M}$ as

$$
\underset{\varepsilon \leftarrow C}{\boldsymbol{M}} = [ [\vec{u}]_\varepsilon\ [\vec{v}]_\varepsilon\ [\vec{w}]_\varepsilon ]
$$

since $\vec{u}, \vec{v}, \vec{w}$ are the basis vectors of C. Obviously, since the target coordinate space is the standard basis
$$
\varepsilon =
\begin{Bmatrix}
\begin{bmatrix}
1 \\ 0 \\ 0
\end{bmatrix},
\begin{bmatrix}
0 \\ 1 \\ 0
\end{bmatrix},
 \begin{bmatrix}
 0 \\ 0 \\ 1
 \end{bmatrix}
\end{Bmatrix}
$$

we are allowed to rewite this as

$$
\underset{\varepsilon \leftarrow C}{\boldsymbol{M}} = [ \vec{u}\ \vec{v}\ \vec{w} ]
$$

since the individual components of the basis vectors represented by the rows of $\boldsymbol{A}$ already are the scalar projections onto the unit vectors of $\varepsilon$.

$\underset{\varepsilon \leftarrow C}{\boldsymbol{M}} = \boldsymbol{A^T}$ is now an orthogonal matrix

$$
\begin{pmatrix}
\vec{u}_x & \vec{v}_x & \vec{w}_x \\
\vec{u}_y & \vec{v}_y & \vec{w}_y \\
\vec{u}_z & \vec{v}_z & \vec{w}_z
\end{pmatrix}
$$

Since

$$
(\underset{\varepsilon \leftarrow C}{\boldsymbol{M}})^{-1} = \underset{C \leftarrow \varepsilon}{\boldsymbol{M}}
$$

and the inverse of an orthogonal matrix is simply its transpose <Cite name="FH22" pp="118" /> it follows that

$$
(\underset{\varepsilon \leftarrow C}{\boldsymbol{M}})^{-1} = (A^T)^{-1} = (A^T)^{T} = A = \underset{C \leftarrow \varepsilon}{\boldsymbol{M}}
$$

This shows that $A$ already provides a change-of-coordinates matrix from $\varepsilon$ to $C$. As such, any vector $\vec{p}$ multiplied with this matrix yields a coordinate vector whose components are the scalar projections of $\vec{p}$ relative to $C$:

$$
A \vec{p} = \underset{C \leftarrow \varepsilon}{\boldsymbol{M}} [\vec{p}]_\varepsilon = [\vec{p}]_C
$$

As such,

$$
\begin{alignat*}{3}
\vec{p'} = {[\vec{p}]_C}_x \vec{u} + {[\vec{p}]_C}_y \vec{v} + {[\vec{p}]_C}_z \vec{w}
\end{alignat*}
$$

$\Box$


:::tip Change-of-Coordinates Example

<Embed
    modeAware={true}
    figref={figures.change_of_coordinates}
    title={
        "The vector v expressed as coordinate vector relative to the bases B and C."}>
    <img src={change_of_coordinates}  />
</Embed>
<details>
<summary>Plot-Code (Python)</summary>

<CodeBlock language="python">
  {change_of_coordinates_code}
</CodeBlock>

</details>

<Figure idx={figures.change_of_coordinates} /> shows two different coordinate systems $B, C$ that both span $\mathbb{R}^2$:

$$
B = \begin{Bmatrix}\vec{b_1}, \ \vec{b_2} \end{Bmatrix} = \begin{Bmatrix}\begin{pmatrix}1 \\ 0\end{pmatrix}, \begin{pmatrix}0 \\1\end{pmatrix}\end{Bmatrix}, C = \begin{Bmatrix}\vec{c_1}, \ \vec{c_2} \end{Bmatrix} =\begin{Bmatrix}\begin{pmatrix}0.5 \\ -0.25\end{pmatrix}, \begin{pmatrix}0.25 \\0.5\end{pmatrix}\end{Bmatrix}
$$

Obviously, since $B = \varepsilon$, the vector $\vec{v} = (6, 2)^T$ can be expressed as

$$
[\vec{v}]_B = \begin{bmatrix} [\vec{b_1}]_B \ [\vec{b_2}]_B   \end{bmatrix}  \begin{pmatrix} 6\\2 \end{pmatrix} = \begin{pmatrix} 1 & 0 \\ 0 & 1 \end{pmatrix} \begin{pmatrix} 6 \\ 2 \end{pmatrix} = \begin{pmatrix} 6 \\ 2 \end{pmatrix}
$$

We now derive the coordinates of $\vec{v}$ relative to the basis $C$.
To construct $[\vec{v}]_C$, we need the columns $[\vec{b_1}]_C$ and $[\vec{b_2}]_C$ of the change-of-coordinates matrix $\underset{C \leftarrow B}{\boldsymbol{P}}$.<br />
These are obtained by expressing the basis vectors of $B$ as linear combinations of the basis vectors of $C$:
$$
\begin{equation}
x_1 \vec{c_1} + x_2 \vec{c_2} = \begin{pmatrix} 1 \\ 0 \end{pmatrix} = \vec{b_1}
\end{equation}
$$

and

$$
\begin{equation}
x_1 \vec{c_1} + x_2 \vec{c_2} = \begin{pmatrix} 0 \\ 1 \end{pmatrix} = \vec{b_2}
\end{equation}
$$

Row-reducing the augmented matrix of _euqation (1)_ yields

$$
\begin{pmatrix}
\begin{array}{cc|c}
0.5   & 0.25 & 1 \\
-0.25 & 0.5  & 0
\end{array}
\end{pmatrix} \sim \begin{pmatrix}\begin{array}{cc|c}
                                  1 & 0 & 1.6 \\
                                  0 & 1 & 0.8
                                  \end{array}\end{pmatrix}
$$

Similiarly, _equation (2)_ gives

$$
\begin{pmatrix}
\begin{array}{cc|c}
0.5   & 0.25 & 0 \\
-0.25 & 0.5  & 1
\end{array}
\end{pmatrix} \sim \begin{pmatrix}\begin{array}{cc|c}
                                  1 & 0 & -0.8 \\
                                  0 & 1 & 1.6
                                  \end{array}\end{pmatrix}
$$

Thus, the change-of-coordinates matrix $\underset{C \leftarrow B}{\boldsymbol{P}}$ is

$$
\underset{C \leftarrow B}{\boldsymbol{P}} = \begin{pmatrix} 1.6 & -0.8 \\ 0.8 & 1.6  \end{pmatrix}
$$

and we finally obtain

$$
[\vec{v}]_C = \begin{bmatrix} [\vec{b_1}]_C \ [\vec{b_1}]_C   \end{bmatrix} [\vec{v}]_B = \begin{pmatrix} 1.6 & -0.8 \\ 0.8 & 1.6  \end{pmatrix} \begin{pmatrix} 6 \\ 2 \end{pmatrix} = \begin{pmatrix} 8 \\ 8\end{pmatrix}
$$

$\Box$
:::



------------------------

_Updates_:
- dd.mm.yyyy Initial publication.
